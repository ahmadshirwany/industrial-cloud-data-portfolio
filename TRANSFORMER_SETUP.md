# Transformer Service Setup Summary

## âœ… Completed

The ETL Transformer service has been created and integrated into the project:

### Files Created
- `services/transformer/transformer_service.py` - ETL pipeline implementation
- `services/transformer/main.py` - Standalone entry point
- `services/transformer/Dockerfile` - Container image definition
- `services/transformer/config/README.md` - Setup documentation
- `scripts/deploy_transformer.sh` - Cloud Run deployment script

### Integration Updates
- âœ… `requirements.txt` - Added psycopg2-binary>=2.9.9
- âœ… `docker-compose.yml` - Added transformer service
- âœ… `.env.example` - Added database credentials template
- âœ… `scripts/run_microservices.ps1` - Added transformer launch
- âœ… `README.md` - Updated architecture and setup docs
- âœ… `DOCKER.md` - Added transformer Docker instructions

## ğŸ¯ Data Pipeline

```
Generator â†’ Pub/Sub â†’ Ingestion â†’ Cloud Storage (JSONL)
                                        â†“
                                   Transformer
                                        â†“
                                   PostgreSQL
```

## ğŸ“‹ Next Steps

### 1. Place Service Account Key

Copy your transformer service account JSON to:
```
services/transformer/config/service-account.json
```

Required permissions:
- `roles/storage.objectViewer` - Read from Cloud Storage
- `roles/cloudsql.client` - Connect to Cloud SQL

### 2. Configure Database Connection

Create `.env` file:
```bash
cp .env.example .env
```

Edit `.env` with your Cloud SQL details:
```env
DB_HOST=your-cloud-sql-ip
DB_NAME=telemetry
DB_USER=postgres
DB_PASSWORD=your-secure-password
```

### 3. Install Dependencies

```powershell
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### 4. Run Services

**Option A: Docker Compose (Recommended)**
```powershell
docker-compose up --build
```

**Option B: Local Development**
```powershell
.\scripts\run_microservices.ps1
```

## ğŸ—„ï¸ Database Schema

The transformer auto-creates these tables on first run:

1. **server_metrics**
   - Stores server telemetry with `disk_utilization` (calculated)
   - Indexes: timestamp, server_id, environment

2. **container_metrics**
   - Stores container stats with `memory_utilization` (calculated)
   - Indexes: timestamp, container_id, service_name

3. **service_metrics**
   - Stores service metrics with `success_rate` (calculated)
   - Indexes: timestamp, service_name, environment

## ğŸ”„ ETL Process

The transformer runs every 60 seconds:
1. **Extract**: Reads JSONL files from Cloud Storage
2. **Transform**: Calculates derived metrics
3. **Load**: Bulk inserts into PostgreSQL with optimized queries

## ğŸ§ª Testing

Verify the pipeline:
```powershell
# Check if data is flowing to Cloud Storage
gsutil ls gs://telemetry-data007/

# Connect to PostgreSQL and verify tables
psql -h $DB_HOST -U $DB_USER -d $DB_NAME
\dt
SELECT COUNT(*) FROM server_metrics;
```

## ğŸ“š Documentation

- `services/transformer/config/README.md` - Detailed setup guide
- `DOCKER.md` - Docker deployment instructions
- `README.md` - Project overview
